{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         f1        f2        f3        f4        f5   response\n0 -0.764216 -1.016209  0.149410 -0.050119 -0.578127   6.242514\n1  0.763880 -1.159509 -0.721492 -0.654067 -0.431670  -8.118241\n2  0.519329 -0.664621 -1.694904  1.339779  0.182764  66.722455\n3 -0.177388  0.515623  0.135144 -0.647634 -0.405631 -27.716793\n4  0.104022  0.749665 -0.939338 -0.090725 -0.639963   8.192075\n5 -0.699867  0.019159  1.103377 -0.671614 -0.119063 -18.597563\n6 -1.028250  0.962967  0.471027 -1.941219 -0.465591 -73.174734\n7  0.337585  1.352948 -1.789795 -0.885796 -0.846150 -25.865464\n8  0.295433 -0.907789  0.275980 -0.675526 -0.942592  -9.001596\n9  0.442269 -0.704559 -1.127342  1.030206  0.800113  57.076963",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.764216</td>\n      <td>-1.016209</td>\n      <td>0.149410</td>\n      <td>-0.050119</td>\n      <td>-0.578127</td>\n      <td>6.242514</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.763880</td>\n      <td>-1.159509</td>\n      <td>-0.721492</td>\n      <td>-0.654067</td>\n      <td>-0.431670</td>\n      <td>-8.118241</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.519329</td>\n      <td>-0.664621</td>\n      <td>-1.694904</td>\n      <td>1.339779</td>\n      <td>0.182764</td>\n      <td>66.722455</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.177388</td>\n      <td>0.515623</td>\n      <td>0.135144</td>\n      <td>-0.647634</td>\n      <td>-0.405631</td>\n      <td>-27.716793</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.104022</td>\n      <td>0.749665</td>\n      <td>-0.939338</td>\n      <td>-0.090725</td>\n      <td>-0.639963</td>\n      <td>8.192075</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.699867</td>\n      <td>0.019159</td>\n      <td>1.103377</td>\n      <td>-0.671614</td>\n      <td>-0.119063</td>\n      <td>-18.597563</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-1.028250</td>\n      <td>0.962967</td>\n      <td>0.471027</td>\n      <td>-1.941219</td>\n      <td>-0.465591</td>\n      <td>-73.174734</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.337585</td>\n      <td>1.352948</td>\n      <td>-1.789795</td>\n      <td>-0.885796</td>\n      <td>-0.846150</td>\n      <td>-25.865464</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.295433</td>\n      <td>-0.907789</td>\n      <td>0.275980</td>\n      <td>-0.675526</td>\n      <td>-0.942592</td>\n      <td>-9.001596</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.442269</td>\n      <td>-0.704559</td>\n      <td>-1.127342</td>\n      <td>1.030206</td>\n      <td>0.800113</td>\n      <td>57.076963</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing dataset to be processed with pandas & displaying the top 10 result\n",
    "dt = pd.read_csv('assignment1_dataset.csv', sep=',')\n",
    "dt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                f1           f2           f3           f4           f5  \\\ncount  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \nmean      0.012255    -0.043030    -0.065785     0.039616     0.008074   \nstd       0.998816     1.042413     0.982640     1.023960     1.006679   \nmin      -3.174809    -3.381691    -3.158010    -2.764936    -2.946633   \n25%      -0.655282    -0.759477    -0.734505    -0.660802    -0.685371   \n50%      -0.001177    -0.038444    -0.049838    -0.006831    -0.000368   \n75%       0.697331     0.696343     0.591642     0.737806     0.710398   \nmax       3.092866     3.534175     3.406115     3.145835     3.007734   \n\n          response  \ncount  1000.000000  \nmean     11.229435  \nstd      40.028188  \nmin    -103.044475  \n25%     -16.580272  \n50%      10.554227  \n75%      38.485118  \nmax     157.890314  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.012255</td>\n      <td>-0.043030</td>\n      <td>-0.065785</td>\n      <td>0.039616</td>\n      <td>0.008074</td>\n      <td>11.229435</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.998816</td>\n      <td>1.042413</td>\n      <td>0.982640</td>\n      <td>1.023960</td>\n      <td>1.006679</td>\n      <td>40.028188</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-3.174809</td>\n      <td>-3.381691</td>\n      <td>-3.158010</td>\n      <td>-2.764936</td>\n      <td>-2.946633</td>\n      <td>-103.044475</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.655282</td>\n      <td>-0.759477</td>\n      <td>-0.734505</td>\n      <td>-0.660802</td>\n      <td>-0.685371</td>\n      <td>-16.580272</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-0.001177</td>\n      <td>-0.038444</td>\n      <td>-0.049838</td>\n      <td>-0.006831</td>\n      <td>-0.000368</td>\n      <td>10.554227</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.697331</td>\n      <td>0.696343</td>\n      <td>0.591642</td>\n      <td>0.737806</td>\n      <td>0.710398</td>\n      <td>38.485118</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.092866</td>\n      <td>3.534175</td>\n      <td>3.406115</td>\n      <td>3.145835</td>\n      <td>3.007734</td>\n      <td>157.890314</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying additional description\n",
    "dt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "f2         -0.031751\nf5         -0.028999\nf3          0.015218\nf1          0.308474\nf4          0.947255\nresponse    1.000000\nName: response, dtype: float64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a correlation matrix between the columns/features and target in ascending order\n",
    "corr_matrix = dt.corr()\n",
    "corr_matrix['response'].sort_values(ascending=True)\n",
    "# Correlation between f4 and response are the closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'relationship between f4 & response')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's plot f4 & response, cuz f4 corr value is close to 1\n",
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(dt.f4, dt.response)\n",
    "plt.xlabel('f4')\n",
    "plt.ylabel('response')\n",
    "plt.title('relationship between f4 & response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         f1        f2        f3        f4        f5   response\n0 -0.764216 -1.016209  0.149410 -0.050119 -0.578127   6.242514\n1  0.763880 -1.159509 -0.721492 -0.654067 -0.431670  -8.118241\n2  0.519329 -0.664621 -1.694904  1.339779  0.182764  66.722455\n3 -0.177388  0.515623  0.135144 -0.647634 -0.405631 -27.716793\n4  0.104022  0.749665 -0.939338 -0.090725 -0.639963   8.192075",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.764216</td>\n      <td>-1.016209</td>\n      <td>0.149410</td>\n      <td>-0.050119</td>\n      <td>-0.578127</td>\n      <td>6.242514</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.763880</td>\n      <td>-1.159509</td>\n      <td>-0.721492</td>\n      <td>-0.654067</td>\n      <td>-0.431670</td>\n      <td>-8.118241</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.519329</td>\n      <td>-0.664621</td>\n      <td>-1.694904</td>\n      <td>1.339779</td>\n      <td>0.182764</td>\n      <td>66.722455</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.177388</td>\n      <td>0.515623</td>\n      <td>0.135144</td>\n      <td>-0.647634</td>\n      <td>-0.405631</td>\n      <td>-27.716793</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.104022</td>\n      <td>0.749665</td>\n      <td>-0.939338</td>\n      <td>-0.090725</td>\n      <td>-0.639963</td>\n      <td>8.192075</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redefine each column to be processed\n",
    "columns = ['f1','f2','f3','f4','f5','response']\n",
    "dt = dt.loc[:, columns]\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the training and test set with the ratio of 8:2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "features = ['f1','f2','f3','f4','f5'] # Data that we want to utilize as training & test\n",
    "#X = dt.loc[:, features] # X are the data we want to use from 'features' = independent variable\n",
    "#y = dt.loc[:, ['response']] # y is the data we want to use as target = dependent variable\n",
    "\n",
    "X_data = np.array(dt.iloc[:,4])\n",
    "y_data = np.array(dt.iloc[:,-1])\n",
    "\n",
    "#X = dt[['f1','f2','f3','f4','f5']]\n",
    "#y = dt['response']\n",
    "#y = np.array((y-y.mean())/y.std())\n",
    "#X = X.apply(lambda rec:(rec-rec.mean())/rec.std(),axis=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state=1, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.84707797e-01 -1.37361359e+00 -1.10308714e+00  2.54715263e-01\n",
      " -1.60024462e+00 -1.14948622e+00  5.72671619e-01  1.11287157e+00\n",
      "  1.22629307e+00 -5.22879722e-01 -1.00285570e-01 -2.34073027e-01\n",
      "  4.38411156e-01  4.98915035e-01 -8.02897555e-01 -1.24190376e+00\n",
      " -1.15685899e-01 -4.65591002e-01 -8.19485690e-02  5.79420592e-01\n",
      "  1.07825039e-01 -2.83557046e-01 -8.55854147e-01 -2.69256619e+00\n",
      " -7.71332965e-01  1.15126654e+00 -2.33394195e-01  1.36647648e+00\n",
      "  8.37936395e-01 -1.48877925e+00  1.48388376e+00  1.97381024e+00\n",
      " -1.04902839e+00  3.00773425e+00 -6.52327286e-01 -2.29933415e-01\n",
      "  5.08284917e-01  8.76084090e-02 -6.62743940e-02  9.53578165e-01\n",
      "  8.09181436e-01 -2.68826397e+00 -1.72185524e+00  5.65847620e-01\n",
      "  2.05657965e+00 -6.36840176e-01 -1.36803424e+00  1.25992606e+00\n",
      "  8.58989121e-01  4.30062768e-01  2.47776525e-01  2.84893257e+00\n",
      " -6.45018880e-01  2.48589339e+00 -2.49280784e-01 -6.02111170e-01\n",
      "  3.10721879e-01 -7.85438107e-01 -1.60124715e-01 -1.02669068e+00\n",
      "  1.59743491e+00 -1.35258658e+00  6.94999865e-01 -8.81276886e-01\n",
      "  2.18240407e-01 -8.95438306e-01  2.38334513e-01 -9.45311963e-01\n",
      "  3.35892736e-01 -2.53349117e-01  4.11419449e-01 -1.77125048e+00\n",
      "  6.95316300e-01  2.79214845e-01  1.25477429e+00  7.29022873e-01\n",
      "  1.26313884e+00  6.09036779e-01  2.75964999e+00 -5.50276226e-01\n",
      "  5.25273224e-01  7.88045330e-02  7.26348564e-01  7.68074948e-01\n",
      "  1.34256381e+00  3.85828150e-02  3.25329224e-01  3.84583872e-01\n",
      " -1.26257868e+00  2.10690554e+00  1.61955138e+00 -2.03516090e-01\n",
      "  3.66129409e-01 -3.51103563e-01 -1.55522391e+00 -4.59254752e-01\n",
      " -2.42011300e-03 -6.71104466e-01 -1.46275538e-01  6.45422295e-01\n",
      "  1.03664818e+00 -7.86013728e-01  1.21416237e+00 -8.79266319e-01\n",
      " -1.01802906e+00 -1.09073931e+00  2.47610628e-01 -2.63740214e-01\n",
      "  1.11359418e+00 -2.44762970e-01  1.56559415e-01 -1.17178527e+00\n",
      "  3.80181526e-01  7.47275491e-01  1.86848457e-01  1.44800499e-01\n",
      " -1.66120883e+00  8.06211505e-01 -5.37821548e-01 -5.92322640e-02\n",
      " -4.04071904e-01  6.46867401e-01 -4.05631086e-01  1.12214088e+00\n",
      " -1.31029042e-01  8.05417595e-01  7.49643640e-02  1.89974100e-01\n",
      " -1.39961789e+00 -2.17497534e+00  1.01031556e+00  6.16080825e-01\n",
      "  1.40269858e+00  1.82764290e-01 -2.47468440e+00 -2.73127827e-01\n",
      " -1.75509799e+00 -6.84231400e-02  5.72992958e-01 -5.17773525e-01\n",
      "  1.14532732e+00  2.56203643e+00 -1.24760250e-01  8.11397944e-01\n",
      " -6.27839236e-01 -7.22706836e-01 -3.65827639e-01 -2.57307926e-01\n",
      " -1.15122018e+00 -2.25658392e+00 -3.76860781e-01 -6.11314110e-02\n",
      " -9.42591940e-01 -8.56943526e-01  4.69064037e-01  2.45790017e+00\n",
      "  5.46968140e-01 -1.03398282e+00 -1.28470347e+00 -1.99824719e+00\n",
      " -1.42856390e+00 -1.52877404e+00 -1.56312069e-01  1.51326448e+00\n",
      " -2.48713331e-01 -7.38706810e-02 -3.31299190e-01  7.85328924e-01\n",
      "  7.46935010e-02  5.14507733e-01 -6.95690255e-01  7.96413773e-01\n",
      " -5.98409123e-01 -5.36200930e-01 -1.01367488e+00 -5.97653604e-01\n",
      "  1.46874159e-01 -2.19870898e-01  2.54536767e-01 -1.36182959e+00\n",
      "  9.94243319e-01 -1.07472037e+00  2.41558580e-02 -8.08108590e-01\n",
      "  1.19225272e+00  7.29526753e-01 -1.21849817e+00  1.17123563e+00\n",
      "  8.52770040e-02  2.37174445e+00 -6.14631112e-01  1.24161849e+00\n",
      " -1.17677049e+00  5.66733883e-01 -8.26788157e-01 -2.25994065e-01\n",
      "  2.88850393e-01  7.09169243e-01  6.40695048e-01 -1.01520089e+00]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "#print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.1 # Set learning rate to 0.1\n",
    "max_epoch = 1000 # Set max iteration to 1000\n",
    "bias = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,) (800,)\n",
      "(200,) (200,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def predictionn(w, X):\n",
    "    # y = (w*x)+b, w = weights, X = input features\n",
    "    yhat = (w * X) + bias\n",
    "    return yhat\n",
    "#prediction(w,X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def loss_fn(y, yhat):\n",
    "    loss = np.sum((y-yhat)**2)/len(y)\n",
    "    return loss\n",
    "#loss_fn(y, prediction(w,X))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train_model(X, y, alpha, max_epoch):\n",
    "    w = b = 0\n",
    "    n = float(len(X))\n",
    "    losses = []\n",
    "    weights = []\n",
    "\n",
    "    for i in range(max_epoch):\n",
    "        def prediction(w, X):\n",
    "            # y = (w*x)+b, w = weights, X = input features\n",
    "            yhat = (w * X) + b\n",
    "            return yhat;\n",
    "        y_predict = prediction(w, X)\n",
    "        loss = loss_fn(y, y_predict)\n",
    "\n",
    "        losses.append(loss)\n",
    "        weights.append(w)\n",
    "        loss = (1/n) * sum([val**2 for val in (y-y_predict)])\n",
    "\n",
    "        wd = -(2/n)*sum(X*(y-y_predict))\n",
    "        bd = -(2/n)*sum(y-y_predict)\n",
    "\n",
    "        w = w - alpha * wd\n",
    "        b = b - alpha * bd\n",
    "\n",
    "        print(f\"Iteration {i+1}: Loss {loss}, Weight {w}, Bias {b}\");\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(weights, losses)\n",
    "    plt.scatter(weights, losses, marker='o', color='red')\n",
    "    plt.title(\"Loss vs Weights\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Weight\")\n",
    "    plt.show()\n",
    "\n",
    "    return w, b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Loss 1745.55215509794, Weight -0.18797553171664952, Bias 2.2673045171457513\n",
      "Iteration 2: Loss 1698.9579709467612, Weight -0.3439976311112525, Bias 4.081575113813229\n",
      "Iteration 3: Loss 1669.1079366380666, Weight -0.4733443720343996, Bias 5.533345992466324\n",
      "Iteration 4: Loss 1649.984129094608, Weight -0.580457661871839, Bias 6.695056504123487\n",
      "Iteration 5: Loss 1637.731751451047, Weight -0.6690671862405067, Bias 7.62466821931012\n",
      "Iteration 6: Loss 1629.8815114209856, Weight -0.7422981049558978, Bias 8.368558866358585\n",
      "Iteration 7: Loss 1624.8515793383533, Weight -0.8027640639455446, Bias 8.963837726677616\n",
      "Iteration 8: Loss 1621.6285964534436, Weight -0.8526471073725101, Bias 9.440198162242678\n",
      "Iteration 9: Loss 1619.5633559203782, Weight -0.8937660242768835, Bias 9.821399819107194\n",
      "Iteration 10: Loss 1618.2399285522852, Weight -0.9276345714052336, Bias 10.126454545459634\n",
      "Iteration 11: Loss 1617.3918296898971, Weight -0.9555108975109259, Bias 10.370575258321285\n",
      "Iteration 12: Loss 1616.8483168432656, Weight -0.9784393673662303, Bias 10.565935149170848\n",
      "Iteration 13: Loss 1616.4999874081639, Weight -0.9972858548583929, Bias 10.72227514344659\n",
      "Iteration 14: Loss 1616.276739380867, Weight -1.0127674495867862, Bias 10.847389948315676\n",
      "Iteration 15: Loss 1616.133651701571, Weight -1.0254774038683843, Bias 10.947516958367633\n",
      "Iteration 16: Loss 1616.0419380326807, Weight -1.0359060389677033, Bias 11.027647436835764\n",
      "Iteration 17: Loss 1615.983150778997, Weight -1.0444582315904554, Bias 11.091775508062417\n",
      "Iteration 18: Loss 1615.9454674194621, Weight -1.0514680143853647, Bias 11.143097391191437\n",
      "Iteration 19: Loss 1615.921310950567, Weight -1.0572107470798506, Bias 11.184170820286894\n",
      "Iteration 20: Loss 1615.9058251115482, Weight -1.061913247334504, Bias 11.217042608074582\n",
      "Iteration 21: Loss 1615.8958972997114, Weight -1.0657622116763315, Bias 11.243350719947268\n",
      "Iteration 22: Loss 1615.8895324244504, Weight -1.0689112061243085, Bias 11.26440595229688\n",
      "Iteration 23: Loss 1615.8854516379672, Weight -1.071486462500302, Bias 11.281257291059338\n",
      "Iteration 24: Loss 1615.8828351694451, Weight -1.0735916790951971, Bias 11.294744211716633\n",
      "Iteration 25: Loss 1615.8811575058699, Weight -1.0753119925534633, Bias 11.305538530203108\n",
      "Iteration 26: Loss 1615.8800817542588, Weight -1.07671726083037, Bias 11.314177892652557\n",
      "Iteration 27: Loss 1615.879391932404, Weight -1.0778647742136462, Bias 11.32109257465307\n",
      "Iteration 28: Loss 1615.8789495684277, Weight -1.0788014921038211, Bias 11.326626926808952\n",
      "Iteration 29: Loss 1615.8786658807528, Weight -1.0795658870006068, Bias 11.331056536271056\n",
      "Iteration 30: Loss 1615.8784839445445, Weight -1.0801894634959102, Bias 11.334601960149639\n",
      "Iteration 31: Loss 1615.8783672593395, Weight -1.0806980086354234, Bias 11.337439715695005\n",
      "Iteration 32: Loss 1615.8782924199056, Weight -1.0811126204414327, Bias 11.339711075282196\n",
      "Iteration 33: Loss 1615.8782444174703, Weight -1.0814505533981795, Bias 11.341529104735013\n",
      "Iteration 34: Loss 1615.878213627155, Weight -1.0817259130384123, Bias 11.342984295905742\n",
      "Iteration 35: Loss 1615.8781938764243, Weight -1.0819502262231926, Bias 11.344149074316666\n",
      "Iteration 36: Loss 1615.8781812066047, Weight -1.082132909095978, Bias 11.345081406568664\n",
      "Iteration 37: Loss 1615.8781730787487, Weight -1.082281650863693, Bias 11.345827687331036\n",
      "Iteration 38: Loss 1615.8781678644061, Weight -1.0824027283828739, Bias 11.346425049805115\n",
      "Iteration 39: Loss 1615.8781645190588, Weight -1.082501263899365, Bias 11.346903214809727\n",
      "Iteration 40: Loss 1615.8781623726993, Weight -1.0825814361141959, Bias 11.347285970635022\n",
      "Iteration 41: Loss 1615.878160995554, Weight -1.0826466529496594, Bias 11.347592357404967\n",
      "Iteration 42: Loss 1615.8781601119115, Weight -1.0826996929041912, Bias 11.34783761495976\n",
      "Iteration 43: Loss 1615.8781595448986, Weight -1.0827428206589984, Bias 11.348033941482871\n",
      "Iteration 44: Loss 1615.878159181045, Weight -1.082777881588867, Bias 11.34819110066526\n",
      "Iteration 45: Loss 1615.8781589475475, Weight -1.0828063789971054, Bias 11.348316907651427\n",
      "Iteration 46: Loss 1615.8781587976973, Weight -1.0828295372092767, Bias 11.348417617971696\n",
      "Iteration 47: Loss 1615.8781587015305, Weight -1.0828483530966175, Bias 11.348498238831365\n",
      "Iteration 48: Loss 1615.8781586398068, Weight -1.0828636381365924, Bias 11.348562778259039\n",
      "Iteration 49: Loss 1615.8781586001915, Weight -1.0828760527372525, Bias 11.348614444520866\n",
      "Iteration 50: Loss 1615.8781585747613, Weight -1.082886134239445, Bias 11.348655805729862\n",
      "Iteration 51: Loss 1615.8781585584395, Weight -1.082894319754351, Bias 11.348688917597006\n",
      "Iteration 52: Loss 1615.8781585479621, Weight -1.082900964783419, Bias 11.348715425683967\n",
      "Iteration 53: Loss 1615.8781585412369, Weight -1.082906358395264, Bias 11.348736647247597\n",
      "Iteration 54: Loss 1615.8781585369181, Weight -1.0829107355927838, Bias 11.34875363674999\n",
      "Iteration 55: Loss 1615.878158534146, Weight -1.0829142873879913, Bias 11.348767238294627\n",
      "Iteration 56: Loss 1615.8781585323657, Weight -1.0829171690073371, Bias 11.348778127598175\n",
      "Iteration 57: Loss 1615.8781585312254, Weight -1.082919506572758, Bias 11.34878684558656\n",
      "Iteration 58: Loss 1615.8781585304926, Weight -1.0829214025402993, Bias 11.348793825287002\n",
      "Iteration 59: Loss 1615.8781585300194, Weight -1.0829229401263227, Bias 11.348799413354012\n",
      "Iteration 60: Loss 1615.8781585297158, Weight -1.0829241869089372, Bias 11.348803887300217\n",
      "Iteration 61: Loss 1615.878158529522, Weight -1.0829251977577032, Bias 11.348807469289227\n",
      "Iteration 62: Loss 1615.8781585293991, Weight -1.0829260172163873, Bias 11.348810337176559\n",
      "Iteration 63: Loss 1615.8781585293184, Weight -1.0829266814404748, Bias 11.348812633347809\n",
      "Iteration 64: Loss 1615.878158529265, Weight -1.0829272197723223, Bias 11.348814471793581\n",
      "Iteration 65: Loss 1615.878158529234, Weight -1.0829276560214698, Bias 11.34881594377301\n",
      "Iteration 66: Loss 1615.8781585292113, Weight -1.0829280095051015, Bias 11.348817122347485\n",
      "Iteration 67: Loss 1615.8781585291993, Weight -1.0829282958934345, Bias 11.348818066009997\n",
      "Iteration 68: Loss 1615.8781585291915, Weight -1.0829285278964849, Bias 11.348818821590532\n",
      "Iteration 69: Loss 1615.878158529183, Weight -1.0829287158218723, Bias 11.348819426581953\n",
      "Iteration 70: Loss 1615.8781585291808, Weight -1.0829288680278122, Bias 11.348819911001957\n",
      "Iteration 71: Loss 1615.8781585291779, Weight -1.0829289912909152, Bias 11.348820298883693\n",
      "Iteration 72: Loss 1615.8781585291754, Weight -1.0829290911047822, Bias 11.348820609469072\n",
      "Iteration 73: Loss 1615.8781585291765, Weight -1.0829291719223662, Bias 11.348820858164101\n",
      "Iteration 74: Loss 1615.8781585291729, Weight -1.0829292373526678, Bias 11.348821057303699\n",
      "Iteration 75: Loss 1615.8781585291736, Weight -1.0829292903203436, Bias 11.348821216764001\n",
      "Iteration 76: Loss 1615.8781585291717, Weight -1.0829293331951995, Bias 11.34882134445256\n",
      "Iteration 77: Loss 1615.8781585291742, Weight -1.082929367897239, Bias 11.348821446700795\n",
      "Iteration 78: Loss 1615.8781585291745, Weight -1.0829293959818673, Bias 11.348821528578208\n",
      "Iteration 79: Loss 1615.8781585291738, Weight -1.0829294187089908, Bias 11.348821594143931\n",
      "Iteration 80: Loss 1615.8781585291733, Weight -1.0829294370990499, Bias 11.348821646648135\n",
      "Iteration 81: Loss 1615.8781585291745, Weight -1.0829294519784474, Bias 11.34882168869327\n",
      "Iteration 82: Loss 1615.8781585291738, Weight -1.0829294640163776, Bias 11.348821722363176\n",
      "Iteration 83: Loss 1615.8781585291715, Weight -1.0829294737546804, Bias 11.348821749326445\n",
      "Iteration 84: Loss 1615.878158529175, Weight -1.0829294816320338, Bias 11.348821770919182\n",
      "Iteration 85: Loss 1615.8781585291756, Weight -1.0829294880035625, Bias 11.348821788211264\n",
      "Iteration 86: Loss 1615.878158529175, Weight -1.0829294931567246, Bias 11.348821802059403\n",
      "Iteration 87: Loss 1615.8781585291758, Weight -1.0829294973241852, Bias 11.348821813149618\n",
      "Iteration 88: Loss 1615.8781585291706, Weight -1.082929500694242, Bias 11.348821822031256\n",
      "Iteration 89: Loss 1615.8781585291747, Weight -1.0829295034192743, Bias 11.348821829144224\n",
      "Iteration 90: Loss 1615.8781585291729, Weight -1.082929505622583, Bias 11.348821834840788\n",
      "Iteration 91: Loss 1615.8781585291729, Weight -1.0829295074039307, Bias 11.348821839403042\n",
      "Iteration 92: Loss 1615.8781585291724, Weight -1.08292950884403, Bias 11.348821843056893\n",
      "Iteration 93: Loss 1615.8781585291727, Weight -1.0829295100081746, Bias 11.348821845983245\n",
      "Iteration 94: Loss 1615.8781585291729, Weight -1.0829295109491817, Bias 11.34882184832697\n",
      "Iteration 95: Loss 1615.8781585291742, Weight -1.082929511709772, Bias 11.348821850204088\n",
      "Iteration 96: Loss 1615.8781585291733, Weight -1.0829295123244964, Bias 11.348821851707509\n",
      "Iteration 97: Loss 1615.8781585291717, Weight -1.0829295128212988, Bias 11.348821852911643\n",
      "Iteration 98: Loss 1615.8781585291708, Weight -1.082929513222775, Bias 11.348821853876078\n",
      "Iteration 99: Loss 1615.8781585291733, Weight -1.0829295135471964, Bias 11.34882185464854\n",
      "Iteration 100: Loss 1615.8781585291727, Weight -1.0829295138093362, Bias 11.348821855267245\n",
      "Iteration 101: Loss 1615.8781585291729, Weight -1.0829295140211395, Bias 11.348821855762804\n",
      "Iteration 102: Loss 1615.8781585291729, Weight -1.0829295141922612, Bias 11.348821856159732\n",
      "Iteration 103: Loss 1615.8781585291747, Weight -1.0829295143305078, Bias 11.348821856477665\n",
      "Iteration 104: Loss 1615.8781585291729, Weight -1.0829295144421887, Bias 11.348821856732325\n",
      "Iteration 105: Loss 1615.8781585291724, Weight -1.0829295145324038, Bias 11.348821856936306\n",
      "Iteration 106: Loss 1615.8781585291736, Weight -1.082929514605275, Bias 11.348821857099695\n",
      "Iteration 107: Loss 1615.8781585291745, Weight -1.0829295146641338, Bias 11.348821857230572\n",
      "Iteration 108: Loss 1615.8781585291724, Weight -1.082929514711672, Bias 11.348821857335409\n",
      "Iteration 109: Loss 1615.8781585291733, Weight -1.0829295147500648, Bias 11.348821857419386\n",
      "Iteration 110: Loss 1615.8781585291742, Weight -1.0829295147810702, Bias 11.348821857486655\n",
      "Iteration 111: Loss 1615.8781585291738, Weight -1.0829295148061089, Bias 11.34882185754054\n",
      "Iteration 112: Loss 1615.8781585291738, Weight -1.0829295148263274, Bias 11.348821857583706\n",
      "Iteration 113: Loss 1615.8781585291722, Weight -1.082929514842653, Bias 11.348821857618285\n",
      "Iteration 114: Loss 1615.8781585291727, Weight -1.0829295148558349, Bias 11.348821857645984\n",
      "Iteration 115: Loss 1615.8781585291733, Weight -1.0829295148664777, Bias 11.348821857668172\n",
      "Iteration 116: Loss 1615.8781585291722, Weight -1.0829295148750702, Bias 11.348821857685948\n",
      "Iteration 117: Loss 1615.8781585291727, Weight -1.082929514882007, Bias 11.348821857700187\n",
      "Iteration 118: Loss 1615.8781585291747, Weight -1.082929514887607, Bias 11.348821857711595\n",
      "Iteration 119: Loss 1615.8781585291713, Weight -1.0829295148921279, Bias 11.348821857720733\n",
      "Iteration 120: Loss 1615.8781585291724, Weight -1.082929514895777, Bias 11.348821857728053\n",
      "Iteration 121: Loss 1615.8781585291756, Weight -1.0829295148987224, Bias 11.348821857733919\n",
      "Iteration 122: Loss 1615.8781585291736, Weight -1.0829295149010996, Bias 11.348821857738617\n",
      "Iteration 123: Loss 1615.8781585291717, Weight -1.0829295149030183, Bias 11.348821857742381\n",
      "Iteration 124: Loss 1615.8781585291729, Weight -1.0829295149045668, Bias 11.348821857745397\n",
      "Iteration 125: Loss 1615.8781585291758, Weight -1.0829295149058167, Bias 11.348821857747813\n",
      "Iteration 126: Loss 1615.8781585291736, Weight -1.0829295149068252, Bias 11.34882185774975\n",
      "Iteration 127: Loss 1615.8781585291713, Weight -1.082929514907639, Bias 11.3488218577513\n",
      "Iteration 128: Loss 1615.8781585291717, Weight -1.0829295149082956, Bias 11.348821857752544\n",
      "Iteration 129: Loss 1615.878158529175, Weight -1.0829295149088254, Bias 11.34882185775354\n",
      "Iteration 130: Loss 1615.8781585291738, Weight -1.082929514909253, Bias 11.348821857754338\n",
      "Iteration 131: Loss 1615.8781585291747, Weight -1.0829295149095979, Bias 11.348821857754977\n",
      "Iteration 132: Loss 1615.8781585291733, Weight -1.0829295149098763, Bias 11.348821857755489\n",
      "Iteration 133: Loss 1615.8781585291733, Weight -1.0829295149101013, Bias 11.3488218577559\n",
      "Iteration 134: Loss 1615.8781585291738, Weight -1.0829295149102822, Bias 11.34882185775623\n",
      "Iteration 135: Loss 1615.8781585291754, Weight -1.0829295149104283, Bias 11.348821857756493\n",
      "Iteration 136: Loss 1615.8781585291727, Weight -1.082929514910546, Bias 11.348821857756704\n",
      "Iteration 137: Loss 1615.878158529175, Weight -1.082929514910641, Bias 11.348821857756873\n",
      "Iteration 138: Loss 1615.8781585291729, Weight -1.082929514910718, Bias 11.348821857757008\n",
      "Iteration 139: Loss 1615.8781585291729, Weight -1.0829295149107798, Bias 11.348821857757116\n",
      "Iteration 140: Loss 1615.8781585291727, Weight -1.0829295149108298, Bias 11.348821857757203\n",
      "Iteration 141: Loss 1615.8781585291738, Weight -1.08292951491087, Bias 11.348821857757274\n",
      "Iteration 142: Loss 1615.8781585291742, Weight -1.0829295149109028, Bias 11.348821857757331\n",
      "Iteration 143: Loss 1615.8781585291727, Weight -1.082929514910929, Bias 11.348821857757375\n",
      "Iteration 144: Loss 1615.8781585291724, Weight -1.0829295149109501, Bias 11.348821857757411\n",
      "Iteration 145: Loss 1615.8781585291733, Weight -1.0829295149109672, Bias 11.34882185775744\n",
      "Iteration 146: Loss 1615.8781585291742, Weight -1.082929514910981, Bias 11.348821857757462\n",
      "Iteration 147: Loss 1615.8781585291742, Weight -1.082929514910992, Bias 11.348821857757482\n",
      "Iteration 148: Loss 1615.8781585291747, Weight -1.082929514911001, Bias 11.348821857757496\n",
      "Iteration 149: Loss 1615.878158529175, Weight -1.0829295149110083, Bias 11.348821857757509\n",
      "Iteration 150: Loss 1615.8781585291754, Weight -1.082929514911014, Bias 11.34882185775752\n",
      "Iteration 151: Loss 1615.878158529175, Weight -1.0829295149110187, Bias 11.348821857757526\n",
      "Iteration 152: Loss 1615.8781585291747, Weight -1.0829295149110225, Bias 11.348821857757532\n",
      "Iteration 153: Loss 1615.8781585291747, Weight -1.0829295149110256, Bias 11.348821857757537\n",
      "Iteration 154: Loss 1615.8781585291747, Weight -1.082929514911028, Bias 11.34882185775754\n",
      "Iteration 155: Loss 1615.8781585291747, Weight -1.08292951491103, Bias 11.348821857757544\n",
      "Iteration 156: Loss 1615.8781585291747, Weight -1.0829295149110318, Bias 11.348821857757546\n",
      "Iteration 157: Loss 1615.8781585291745, Weight -1.0829295149110334, Bias 11.348821857757548\n",
      "Iteration 158: Loss 1615.8781585291745, Weight -1.0829295149110345, Bias 11.34882185775755\n",
      "Iteration 159: Loss 1615.8781585291745, Weight -1.0829295149110354, Bias 11.34882185775755\n",
      "Iteration 160: Loss 1615.8781585291745, Weight -1.082929514911036, Bias 11.34882185775755\n",
      "Iteration 161: Loss 1615.8781585291745, Weight -1.0829295149110365, Bias 11.34882185775755\n",
      "Iteration 162: Loss 1615.8781585291745, Weight -1.082929514911037, Bias 11.34882185775755\n",
      "Iteration 163: Loss 1615.8781585291745, Weight -1.0829295149110372, Bias 11.34882185775755\n",
      "Iteration 164: Loss 1615.8781585291745, Weight -1.0829295149110374, Bias 11.34882185775755\n",
      "Iteration 165: Loss 1615.8781585291745, Weight -1.0829295149110376, Bias 11.34882185775755\n",
      "Iteration 166: Loss 1615.8781585291745, Weight -1.0829295149110378, Bias 11.34882185775755\n",
      "Iteration 167: Loss 1615.8781585291745, Weight -1.082929514911038, Bias 11.34882185775755\n",
      "Iteration 168: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 169: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 170: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 171: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 172: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 173: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 174: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 175: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 176: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 177: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 178: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 179: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 180: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 181: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 182: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 183: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 184: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 185: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 186: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 187: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 188: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 189: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 190: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 191: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 192: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 193: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 194: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 195: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 196: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 197: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 198: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 199: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 200: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 201: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 202: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 203: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 204: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 205: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 206: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 207: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 208: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 209: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 210: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 211: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 212: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 213: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 214: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 215: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 216: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 217: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 218: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 219: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 220: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 221: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 222: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 223: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 224: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 225: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 226: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 227: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 228: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 229: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 230: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 231: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 232: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 233: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 234: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 235: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 236: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 237: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 238: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 239: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 240: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 241: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 242: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 243: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 244: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 245: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 246: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 247: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 248: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 249: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 250: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 251: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 252: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 253: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 254: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 255: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 256: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 257: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 258: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 259: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 260: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 261: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 262: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 263: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 264: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 265: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 266: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 267: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 268: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 269: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 270: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 271: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 272: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 273: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 274: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 275: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 276: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 277: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 278: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 279: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 280: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 281: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 282: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 283: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 284: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 285: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 286: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 287: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 288: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 289: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 290: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 291: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 292: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 293: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 294: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 295: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 296: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 297: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 298: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 299: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 300: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 301: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 302: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 303: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 304: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 305: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 306: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 307: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 308: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 309: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 310: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 311: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 312: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 313: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 314: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 315: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 316: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 317: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 318: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 319: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 320: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 321: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 322: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 323: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 324: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 325: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 326: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 327: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 328: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 329: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 330: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 331: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 332: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 333: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 334: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 335: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 336: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 337: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 338: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 339: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 340: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 341: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 342: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 343: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 344: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 345: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 346: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 347: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 348: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 349: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 350: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 351: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 352: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 353: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 354: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 355: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 356: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 357: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 358: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 359: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 360: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 361: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 362: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 363: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 364: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 365: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 366: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 367: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 368: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 369: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 370: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 371: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 372: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 373: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 374: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 375: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 376: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 377: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 378: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 379: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 380: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 381: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 382: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 383: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 384: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 385: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 386: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 387: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 388: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 389: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 390: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 391: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 392: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 393: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 394: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 395: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 396: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 397: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 398: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 399: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 400: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 401: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 402: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 403: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 404: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 405: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 406: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 407: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 408: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 409: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 410: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 411: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 412: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 413: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 414: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 415: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 416: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 417: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 418: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 419: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 420: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 421: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 422: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 423: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 424: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 425: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 426: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 427: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 428: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 429: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 430: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 431: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 432: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 433: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 434: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 435: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 436: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 437: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 438: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 439: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 440: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 441: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 442: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 443: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 444: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 445: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 446: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 447: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 448: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 449: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 450: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 451: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 452: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 453: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 454: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 455: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 456: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 457: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 458: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 459: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 460: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 461: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 462: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 463: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 464: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 465: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 466: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 467: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 468: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 469: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 470: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 471: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 472: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 473: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 474: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 475: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 476: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 477: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 478: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 479: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 480: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 481: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 482: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 483: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 484: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 485: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 486: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 487: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 488: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 489: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 490: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 491: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 492: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 493: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 494: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 495: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 496: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 497: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 498: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 499: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 500: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 501: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 502: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 503: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 504: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 505: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 506: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 507: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 508: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 509: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 510: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 511: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 512: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 513: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 514: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 515: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 516: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 517: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 518: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 519: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 520: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 521: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 522: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 523: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 524: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 525: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 526: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 527: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 528: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 529: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 530: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 531: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 532: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 533: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 534: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 535: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 536: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 537: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 538: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 539: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 540: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 541: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 542: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 543: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 544: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 545: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 546: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 547: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 548: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 549: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 550: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 551: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 552: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 553: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 554: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 555: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 556: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 557: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 558: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 559: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 560: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 561: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 562: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 563: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 564: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 565: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 566: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 567: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 568: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 569: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 570: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 571: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 572: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 573: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 574: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 575: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 576: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 577: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 578: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 579: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 580: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 581: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 582: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 583: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 584: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 585: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 586: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 587: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 588: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 589: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 590: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 591: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 592: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 593: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 594: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 595: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 596: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 597: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 598: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 599: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 600: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 601: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 602: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 603: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 604: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 605: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 606: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 607: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 608: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 609: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 610: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 611: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 612: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 613: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 614: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 615: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 616: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 617: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 618: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 619: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 620: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 621: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 622: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 623: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 624: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 625: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 626: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 627: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 628: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 629: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 630: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 631: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 632: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 633: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 634: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 635: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 636: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 637: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 638: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 639: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 640: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 641: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 642: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 643: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 644: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 645: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 646: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 647: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 648: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 649: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 650: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 651: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 652: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 653: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 654: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 655: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 656: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 657: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 658: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 659: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 660: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 661: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 662: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 663: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 664: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 665: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 666: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 667: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 668: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 669: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 670: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 671: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 672: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 673: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 674: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 675: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 676: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 677: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 678: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 679: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 680: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 681: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 682: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 683: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 684: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 685: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 686: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 687: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 688: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 689: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 690: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 691: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 692: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 693: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 694: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 695: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 696: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 697: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 698: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 699: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 700: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 701: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 702: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 703: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 704: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 705: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 706: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 707: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 708: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 709: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 710: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 711: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 712: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 713: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 714: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 715: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 716: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 717: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 718: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 719: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 720: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 721: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 722: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 723: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 724: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 725: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 726: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 727: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 728: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 729: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 730: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 731: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 732: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 733: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 734: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 735: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 736: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 737: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 738: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 739: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 740: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 741: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 742: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 743: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 744: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 745: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 746: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 747: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 748: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 749: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 750: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 751: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 752: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 753: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 754: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 755: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 756: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 757: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 758: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 759: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 760: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 761: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 762: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 763: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 764: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 765: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 766: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 767: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 768: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 769: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 770: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 771: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 772: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 773: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 774: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 775: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 776: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 777: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 778: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 779: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 780: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 781: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 782: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 783: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 784: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 785: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 786: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 787: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 788: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 789: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 790: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 791: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 792: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 793: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 794: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 795: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 796: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 797: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 798: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 799: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 800: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 801: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 802: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 803: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 804: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 805: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 806: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 807: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 808: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 809: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 810: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 811: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 812: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 813: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 814: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 815: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 816: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 817: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 818: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 819: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 820: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 821: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 822: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 823: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 824: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 825: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 826: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 827: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 828: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 829: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 830: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 831: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 832: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 833: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 834: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 835: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 836: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 837: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 838: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 839: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 840: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 841: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 842: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 843: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 844: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 845: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 846: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 847: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 848: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 849: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 850: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 851: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 852: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 853: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 854: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 855: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 856: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 857: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 858: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 859: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 860: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 861: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 862: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 863: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 864: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 865: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 866: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 867: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 868: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 869: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 870: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 871: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 872: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 873: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 874: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 875: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 876: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 877: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 878: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 879: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 880: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 881: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 882: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 883: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 884: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 885: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 886: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 887: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 888: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 889: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 890: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 891: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 892: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 893: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 894: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 895: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 896: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 897: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 898: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 899: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 900: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 901: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 902: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 903: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 904: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 905: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 906: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 907: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 908: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 909: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 910: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 911: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 912: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 913: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 914: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 915: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 916: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 917: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 918: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 919: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 920: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 921: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 922: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 923: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 924: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 925: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 926: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 927: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 928: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 929: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 930: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 931: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 932: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 933: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 934: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 935: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 936: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 937: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 938: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 939: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 940: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 941: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 942: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 943: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 944: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 945: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 946: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 947: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 948: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 949: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 950: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 951: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 952: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 953: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 954: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 955: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 956: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 957: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 958: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 959: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 960: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 961: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 962: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 963: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 964: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 965: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 966: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 967: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 968: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 969: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 970: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 971: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 972: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 973: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 974: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 975: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 976: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 977: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 978: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 979: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 980: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 981: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 982: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 983: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 984: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 985: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 986: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 987: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 988: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 989: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 990: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 991: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 992: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 993: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 994: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 995: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 996: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 997: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 998: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 999: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 1000: Loss 1615.8781585291745, Weight -1.0829295149110383, Bias 11.34882185775755\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Weight: -1.0829295149110383\n",
      "Estimated Bias: 11.34882185775755\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 864x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "est_weight, est_bias = train_model(X_train, y_train, alpha, max_epoch)\n",
    "print(f\"Estimated Weight: {est_weight}\\nEstimated Bias: {est_bias}\")\n",
    "y_pred = est_weight*y_test + est_bias\n",
    "plt.figure(figsize = (12,10))\n",
    "plt.scatter(X_test, y_test, marker='o', color='red')\n",
    "\n",
    "plt.plot([min(X_test), max(X_test)], [min(y_pred), max(y_pred)], color='blue')\n",
    "\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 11.5909469 , -46.23433884,  13.41193567,  58.94509245,\n        16.80814183, -32.07360704, -11.46905768,  67.96054832,\n        63.36064179,   7.43418294, -75.19501229, -80.51367862,\n        65.00751397, -26.03136075,   2.33286578, -37.62951731,\n        92.56514751,  90.59190087, -50.22738733,   0.94338296,\n       -73.47688757, -84.98172629,  51.18621094,  -2.43861932,\n        28.91329077,  49.50171602,  12.49680211, -45.04138888,\n         9.12994773, -42.85458043,  -2.71938157,  74.65536645,\n       -13.01161853,  16.41917507, -55.55657187, -10.64751477,\n        50.07911971,  47.12987469,  44.96456405,  32.80679649,\n       -32.91731199,  70.99508486, -15.14961542, -67.70116387,\n       -24.9849732 ,   1.32946312,  -9.89208915,  24.88767981,\n        10.15183168, -26.75061849,  48.41945328, -68.52615808,\n        -7.70818164, -46.46980742, -29.90871636,  27.15895018,\n       -57.97267284, -58.05624732, -16.14658229, -38.33553699,\n         5.52465377,  82.94385197, -12.9818163 ,  31.03002806,\n       -31.82286578,  16.45481201,  99.97897628,  24.52775043,\n        41.68125343,  54.38792151,  30.45059798,  24.78149133,\n       -47.14561741, -38.64127268,  80.98804361, -49.19048232,\n       -86.45021202,  22.83638526, -10.26062886,  31.74244531,\n        41.05546838, -15.10021177, -30.49590481,  24.91750482,\n         0.97617678, -30.22660223, -29.07228776,  76.99571952,\n       -67.01267692,   6.59504498, -10.50164832, -19.94332576,\n       -24.58220535,  14.28591015, -54.94115067,   8.77308831,\n        35.65952664,  29.53553951,  15.43297086,  -6.98037341,\n        34.95645912, -17.7158983 , -24.71833604,  -5.90537556,\n         9.78121968,  88.70272839, -30.3252232 ,  18.08373114,\n        29.26432176,  39.15039384,  -0.63292482,  45.5912655 ,\n        14.22973247,  31.70009042, -29.22968809, -36.94037986,\n       -99.27427503, -19.97574837,  25.0594858 ,  14.63563834,\n       -22.54663644,  26.9481244 ,  41.36415515,  -3.69166109,\n       -43.17408933,   2.49705669,  -8.47992153,  -7.12469789,\n        10.68011785,   8.67094792,   1.17584384, -17.10817213,\n        81.28650344, -60.90689449, -35.13644506,  17.20719702,\n        -6.30381612,  26.37007349, -32.50575804,  14.39360514,\n         9.97773902, -26.02485332, -83.33700169, -89.54897788,\n         5.76080924, -31.29338314,  63.64681492,  39.91305749,\n        18.47993729,  18.37622556,  17.82242296,  57.69826276,\n        21.09691629, -34.43438259,  -0.25877616,  52.75948172,\n        35.5653559 , -24.76713637,  -8.99262882,   2.172859  ,\n       -53.7545424 , -24.04883376,  -6.35778571, -21.84350635,\n        -6.10584479, -93.67284046, -35.62249618, -43.55017059,\n        48.74780834, -16.85094332, -12.59727183,  81.01850694,\n        52.16933016, -20.48500703,  37.97139062,  -3.2376965 ,\n       -44.29450195,   1.90342207,  -2.26008553,  51.43655277,\n       -61.28549663, -94.8991513 , -26.85148534, -12.29694448,\n        30.7021584 , -53.89579895,  14.04904008,  34.80087859,\n        54.75155939,  80.86545886, -31.75898596, -12.26180807,\n        33.60687299,  -8.44258801,   4.20191565, -61.65899424,\n       -46.46737444,  46.02249321, -81.42469858, -27.34744472])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ -0.22358338,  53.17350751,  -1.9051229 , -43.95140213,\n        -5.04125144,  40.09718851,  21.07051218, -52.27646461,\n       -48.02881371,   3.61486031,  79.91640541,  84.8277743 ,\n       -49.54957028,  34.51765059,   8.32552438,  45.22763346,\n       -74.99687148, -73.17473383,  56.86077288,   9.60860218,\n        78.32985274,  88.95366395, -36.78668698,  12.73161456,\n       -16.21940179, -35.23118877,  -1.06006922,  52.07191231,\n         2.04895527,  50.05256717,  12.99087635, -58.45860116,\n        22.49494547,  -4.68207131,  61.7818545 ,  20.3118821 ,\n       -35.76437554, -33.04098036, -31.04148675, -19.81474725,\n        40.87628349, -55.07861978,  24.46921698,  72.99642741,\n        33.55139421,   9.2520876 ,  19.61430612, -12.50206755,\n         1.10532603,  35.18182839, -34.23180448,  73.7582445 ,\n        17.59763977,  53.39094418,  38.0980827 , -14.59940661,\n        64.0129332 ,  64.09010764,  25.38983726,  45.87958696,\n         5.3781599 , -66.11236385,  22.46742546, -18.17404174,\n        39.86564873,  -4.71497922, -81.84295765, -12.16970116,\n       -28.00960834, -39.74321418, -17.63898376, -12.40401087,\n        54.0150014 ,  46.16190975, -64.30632908,  55.90327288,\n        90.3096947 , -10.60785882,  19.95462347, -18.83190288,\n       -27.4317452 ,  24.42359661,  38.64030492, -12.5296086 ,\n         9.57831967,  38.39162523,  37.32570685, -60.61973264,\n        72.36066401,   4.38973803,  20.17718594,  28.89583042,\n        33.17946987,  -2.7121694 ,  61.21356156,   2.37848679,\n       -22.44901856, -16.79399943,  -3.7713895 ,  16.92556627,\n       -21.79979116,  26.83897683,  33.30517582,  15.93289053,\n         1.44755698, -71.43023204,  38.48269392,  -6.21915756,\n       -16.54355122, -25.67255911,  11.0641981 , -31.62019612,\n        -2.66029374, -18.79279148,  37.47105365,  44.59126938,\n       102.1517055 ,  28.92577014, -12.66071684,  -3.03511581,\n        31.29978252, -14.40472563, -27.71679309,  13.88869981,\n        50.34760844,   8.17390703,  18.31028069,  17.05883854,\n         0.61749541,   2.47280539,   9.39394289,  26.27778964,\n       -64.58193319,  66.72245548,  42.92547786,  -5.40974743,\n        16.30081897, -13.87094121,  40.49624587,  -2.81161723,\n         1.26608686,  34.51164149,  87.43489049,  93.17116059,\n         5.16008895,  39.37671327, -48.29307203, -26.37681884,\n        -6.5850227 ,  -6.48925309,  -5.97786007, -42.80005325,\n        -9.00159641,  42.27717854,  10.71870132, -38.23947846,\n       -22.36205931,  33.35023908,  18.78372544,   8.47327802,\n        60.11782241,  32.68694327,  16.35065563,  30.65049733,\n        16.11800806,  96.97922244,  43.37430774,  50.69488983,\n       -34.53501448,  26.04025912,  22.11232897, -64.33445956,\n       -37.69452004,  29.39603035, -24.58384262,  13.46949931,\n        51.38222113,   8.72208178,  12.56675268, -37.01785791,\n        67.0720647 ,  98.11162379,  35.27497097,  21.83500035,\n       -17.87127996,  60.24826169,  -2.49343857, -21.65612481,\n       -40.07900508, -64.19313173,  39.80666075,  21.80255465,\n       -20.5535548 ,  18.27580613,   6.59960423,  67.41696028,\n        53.38869751, -32.0184009 ,  85.66902939,  35.73295034])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}