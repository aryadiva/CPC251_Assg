{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         f1        f2        f3        f4        f5   response\n0 -0.764216 -1.016209  0.149410 -0.050119 -0.578127   6.242514\n1  0.763880 -1.159509 -0.721492 -0.654067 -0.431670  -8.118241\n2  0.519329 -0.664621 -1.694904  1.339779  0.182764  66.722455\n3 -0.177388  0.515623  0.135144 -0.647634 -0.405631 -27.716793\n4  0.104022  0.749665 -0.939338 -0.090725 -0.639963   8.192075\n5 -0.699867  0.019159  1.103377 -0.671614 -0.119063 -18.597563\n6 -1.028250  0.962967  0.471027 -1.941219 -0.465591 -73.174734\n7  0.337585  1.352948 -1.789795 -0.885796 -0.846150 -25.865464\n8  0.295433 -0.907789  0.275980 -0.675526 -0.942592  -9.001596\n9  0.442269 -0.704559 -1.127342  1.030206  0.800113  57.076963",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.764216</td>\n      <td>-1.016209</td>\n      <td>0.149410</td>\n      <td>-0.050119</td>\n      <td>-0.578127</td>\n      <td>6.242514</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.763880</td>\n      <td>-1.159509</td>\n      <td>-0.721492</td>\n      <td>-0.654067</td>\n      <td>-0.431670</td>\n      <td>-8.118241</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.519329</td>\n      <td>-0.664621</td>\n      <td>-1.694904</td>\n      <td>1.339779</td>\n      <td>0.182764</td>\n      <td>66.722455</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.177388</td>\n      <td>0.515623</td>\n      <td>0.135144</td>\n      <td>-0.647634</td>\n      <td>-0.405631</td>\n      <td>-27.716793</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.104022</td>\n      <td>0.749665</td>\n      <td>-0.939338</td>\n      <td>-0.090725</td>\n      <td>-0.639963</td>\n      <td>8.192075</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.699867</td>\n      <td>0.019159</td>\n      <td>1.103377</td>\n      <td>-0.671614</td>\n      <td>-0.119063</td>\n      <td>-18.597563</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-1.028250</td>\n      <td>0.962967</td>\n      <td>0.471027</td>\n      <td>-1.941219</td>\n      <td>-0.465591</td>\n      <td>-73.174734</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.337585</td>\n      <td>1.352948</td>\n      <td>-1.789795</td>\n      <td>-0.885796</td>\n      <td>-0.846150</td>\n      <td>-25.865464</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.295433</td>\n      <td>-0.907789</td>\n      <td>0.275980</td>\n      <td>-0.675526</td>\n      <td>-0.942592</td>\n      <td>-9.001596</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.442269</td>\n      <td>-0.704559</td>\n      <td>-1.127342</td>\n      <td>1.030206</td>\n      <td>0.800113</td>\n      <td>57.076963</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing dataset to be processed with pandas & displaying the top 10 result\n",
    "dt = pd.read_csv('assignment1_dataset.csv', sep=',')\n",
    "dt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                f1           f2           f3           f4           f5  \\\ncount  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \nmean      0.012255    -0.043030    -0.065785     0.039616     0.008074   \nstd       0.998816     1.042413     0.982640     1.023960     1.006679   \nmin      -3.174809    -3.381691    -3.158010    -2.764936    -2.946633   \n25%      -0.655282    -0.759477    -0.734505    -0.660802    -0.685371   \n50%      -0.001177    -0.038444    -0.049838    -0.006831    -0.000368   \n75%       0.697331     0.696343     0.591642     0.737806     0.710398   \nmax       3.092866     3.534175     3.406115     3.145835     3.007734   \n\n          response  \ncount  1000.000000  \nmean     11.229435  \nstd      40.028188  \nmin    -103.044475  \n25%     -16.580272  \n50%      10.554227  \n75%      38.485118  \nmax     157.890314  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.012255</td>\n      <td>-0.043030</td>\n      <td>-0.065785</td>\n      <td>0.039616</td>\n      <td>0.008074</td>\n      <td>11.229435</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.998816</td>\n      <td>1.042413</td>\n      <td>0.982640</td>\n      <td>1.023960</td>\n      <td>1.006679</td>\n      <td>40.028188</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-3.174809</td>\n      <td>-3.381691</td>\n      <td>-3.158010</td>\n      <td>-2.764936</td>\n      <td>-2.946633</td>\n      <td>-103.044475</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>-0.655282</td>\n      <td>-0.759477</td>\n      <td>-0.734505</td>\n      <td>-0.660802</td>\n      <td>-0.685371</td>\n      <td>-16.580272</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>-0.001177</td>\n      <td>-0.038444</td>\n      <td>-0.049838</td>\n      <td>-0.006831</td>\n      <td>-0.000368</td>\n      <td>10.554227</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.697331</td>\n      <td>0.696343</td>\n      <td>0.591642</td>\n      <td>0.737806</td>\n      <td>0.710398</td>\n      <td>38.485118</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.092866</td>\n      <td>3.534175</td>\n      <td>3.406115</td>\n      <td>3.145835</td>\n      <td>3.007734</td>\n      <td>157.890314</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying additional description\n",
    "dt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "f2         -0.031751\nf5         -0.028999\nf3          0.015218\nf1          0.308474\nf4          0.947255\nresponse    1.000000\nName: response, dtype: float64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a correlation matrix between the columns/features and target in ascending order\n",
    "corr_matrix = dt.corr()\n",
    "corr_matrix['response'].sort_values(ascending=True)\n",
    "# Correlation between f4 and response are the closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'relationship between f4 & response')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's plot f4 & response, cuz f4 corr value is close to 1\n",
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(dt.f4, dt.response)\n",
    "plt.xlabel('f4')\n",
    "plt.ylabel('response')\n",
    "plt.title('relationship between f4 & response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         f1        f2        f3        f4        f5   response\n0 -0.764216 -1.016209  0.149410 -0.050119 -0.578127   6.242514\n1  0.763880 -1.159509 -0.721492 -0.654067 -0.431670  -8.118241\n2  0.519329 -0.664621 -1.694904  1.339779  0.182764  66.722455\n3 -0.177388  0.515623  0.135144 -0.647634 -0.405631 -27.716793\n4  0.104022  0.749665 -0.939338 -0.090725 -0.639963   8.192075",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.764216</td>\n      <td>-1.016209</td>\n      <td>0.149410</td>\n      <td>-0.050119</td>\n      <td>-0.578127</td>\n      <td>6.242514</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.763880</td>\n      <td>-1.159509</td>\n      <td>-0.721492</td>\n      <td>-0.654067</td>\n      <td>-0.431670</td>\n      <td>-8.118241</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.519329</td>\n      <td>-0.664621</td>\n      <td>-1.694904</td>\n      <td>1.339779</td>\n      <td>0.182764</td>\n      <td>66.722455</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.177388</td>\n      <td>0.515623</td>\n      <td>0.135144</td>\n      <td>-0.647634</td>\n      <td>-0.405631</td>\n      <td>-27.716793</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.104022</td>\n      <td>0.749665</td>\n      <td>-0.939338</td>\n      <td>-0.090725</td>\n      <td>-0.639963</td>\n      <td>8.192075</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redefine each column to be processed\n",
    "columns = ['f1','f2','f3','f4','f5','response']\n",
    "dt = dt.loc[:, columns]\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the training and test set with the ratio of 8:2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "features = ['f1','f2','f3','f4','f5'] # Data that we want to utilize as training & test\n",
    "#X = dt.loc[:, features] # X are the data we want to use from 'features' = independent variable\n",
    "#y = dt.loc[:, ['response']] # y is the data we want to use as target = dependent variable\n",
    "\n",
    "X_data = np.array(dt.iloc[:,4])\n",
    "y_data = np.array(dt.iloc[:,-1])\n",
    "\n",
    "#X = dt[['f1','f2','f3','f4','f5']]\n",
    "#y = dt['response']\n",
    "#y = np.array((y-y.mean())/y.std())\n",
    "#X = X.apply(lambda rec:(rec-rec.mean())/rec.std(),axis=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, random_state=1, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.84707797e-01 -1.37361359e+00 -1.10308714e+00  2.54715263e-01\n",
      " -1.60024462e+00 -1.14948622e+00  5.72671619e-01  1.11287157e+00\n",
      "  1.22629307e+00 -5.22879722e-01 -1.00285570e-01 -2.34073027e-01\n",
      "  4.38411156e-01  4.98915035e-01 -8.02897555e-01 -1.24190376e+00\n",
      " -1.15685899e-01 -4.65591002e-01 -8.19485690e-02  5.79420592e-01\n",
      "  1.07825039e-01 -2.83557046e-01 -8.55854147e-01 -2.69256619e+00\n",
      " -7.71332965e-01  1.15126654e+00 -2.33394195e-01  1.36647648e+00\n",
      "  8.37936395e-01 -1.48877925e+00  1.48388376e+00  1.97381024e+00\n",
      " -1.04902839e+00  3.00773425e+00 -6.52327286e-01 -2.29933415e-01\n",
      "  5.08284917e-01  8.76084090e-02 -6.62743940e-02  9.53578165e-01\n",
      "  8.09181436e-01 -2.68826397e+00 -1.72185524e+00  5.65847620e-01\n",
      "  2.05657965e+00 -6.36840176e-01 -1.36803424e+00  1.25992606e+00\n",
      "  8.58989121e-01  4.30062768e-01  2.47776525e-01  2.84893257e+00\n",
      " -6.45018880e-01  2.48589339e+00 -2.49280784e-01 -6.02111170e-01\n",
      "  3.10721879e-01 -7.85438107e-01 -1.60124715e-01 -1.02669068e+00\n",
      "  1.59743491e+00 -1.35258658e+00  6.94999865e-01 -8.81276886e-01\n",
      "  2.18240407e-01 -8.95438306e-01  2.38334513e-01 -9.45311963e-01\n",
      "  3.35892736e-01 -2.53349117e-01  4.11419449e-01 -1.77125048e+00\n",
      "  6.95316300e-01  2.79214845e-01  1.25477429e+00  7.29022873e-01\n",
      "  1.26313884e+00  6.09036779e-01  2.75964999e+00 -5.50276226e-01\n",
      "  5.25273224e-01  7.88045330e-02  7.26348564e-01  7.68074948e-01\n",
      "  1.34256381e+00  3.85828150e-02  3.25329224e-01  3.84583872e-01\n",
      " -1.26257868e+00  2.10690554e+00  1.61955138e+00 -2.03516090e-01\n",
      "  3.66129409e-01 -3.51103563e-01 -1.55522391e+00 -4.59254752e-01\n",
      " -2.42011300e-03 -6.71104466e-01 -1.46275538e-01  6.45422295e-01\n",
      "  1.03664818e+00 -7.86013728e-01  1.21416237e+00 -8.79266319e-01\n",
      " -1.01802906e+00 -1.09073931e+00  2.47610628e-01 -2.63740214e-01\n",
      "  1.11359418e+00 -2.44762970e-01  1.56559415e-01 -1.17178527e+00\n",
      "  3.80181526e-01  7.47275491e-01  1.86848457e-01  1.44800499e-01\n",
      " -1.66120883e+00  8.06211505e-01 -5.37821548e-01 -5.92322640e-02\n",
      " -4.04071904e-01  6.46867401e-01 -4.05631086e-01  1.12214088e+00\n",
      " -1.31029042e-01  8.05417595e-01  7.49643640e-02  1.89974100e-01\n",
      " -1.39961789e+00 -2.17497534e+00  1.01031556e+00  6.16080825e-01\n",
      "  1.40269858e+00  1.82764290e-01 -2.47468440e+00 -2.73127827e-01\n",
      " -1.75509799e+00 -6.84231400e-02  5.72992958e-01 -5.17773525e-01\n",
      "  1.14532732e+00  2.56203643e+00 -1.24760250e-01  8.11397944e-01\n",
      " -6.27839236e-01 -7.22706836e-01 -3.65827639e-01 -2.57307926e-01\n",
      " -1.15122018e+00 -2.25658392e+00 -3.76860781e-01 -6.11314110e-02\n",
      " -9.42591940e-01 -8.56943526e-01  4.69064037e-01  2.45790017e+00\n",
      "  5.46968140e-01 -1.03398282e+00 -1.28470347e+00 -1.99824719e+00\n",
      " -1.42856390e+00 -1.52877404e+00 -1.56312069e-01  1.51326448e+00\n",
      " -2.48713331e-01 -7.38706810e-02 -3.31299190e-01  7.85328924e-01\n",
      "  7.46935010e-02  5.14507733e-01 -6.95690255e-01  7.96413773e-01\n",
      " -5.98409123e-01 -5.36200930e-01 -1.01367488e+00 -5.97653604e-01\n",
      "  1.46874159e-01 -2.19870898e-01  2.54536767e-01 -1.36182959e+00\n",
      "  9.94243319e-01 -1.07472037e+00  2.41558580e-02 -8.08108590e-01\n",
      "  1.19225272e+00  7.29526753e-01 -1.21849817e+00  1.17123563e+00\n",
      "  8.52770040e-02  2.37174445e+00 -6.14631112e-01  1.24161849e+00\n",
      " -1.17677049e+00  5.66733883e-01 -8.26788157e-01 -2.25994065e-01\n",
      "  2.88850393e-01  7.09169243e-01  6.40695048e-01 -1.01520089e+00]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "#print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.1 # Set learning rate to 0.1\n",
    "max_epoch = 1000 # Set max iteration to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,) (800,)\n",
      "(200,) (200,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def loss_fn(y, yhat):\n",
    "    loss = np.sum((y-yhat)**2)/len(y)\n",
    "    return loss\n",
    "#loss_fn(y, prediction(w,X))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def train_model(X, y, alpha, max_epoch):\n",
    "    w = b = 0\n",
    "    n = float(len(X))\n",
    "    losses = []\n",
    "    weights = []\n",
    "\n",
    "    for i in range(max_epoch):\n",
    "        def prediction(w, X):\n",
    "            yhat = (w * X) + b\n",
    "            return yhat;\n",
    "        y_predict = prediction(w, X)\n",
    "        loss = loss_fn(y, y_predict)\n",
    "\n",
    "        losses.append(loss)\n",
    "        weights.append(w)\n",
    "\n",
    "        #loss = (1/n) * sum([val**2 for val in (y-y_predict)])\n",
    "        loss_fn(y, y_predict)\n",
    "\n",
    "        wd = -(2/n)*sum(X*(y-y_predict))\n",
    "        bd = -(2/n)*sum(y-y_predict)\n",
    "\n",
    "        w = w - alpha * wd\n",
    "        b = b - alpha * bd\n",
    "\n",
    "        print(f\"Iteration {i+1}: Loss {loss}, Weight {w}, Bias {b}\");\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(weights, losses)\n",
    "    plt.scatter(weights, losses, marker='o', color='red')\n",
    "    plt.title(\"Loss vs Weights\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Weight\")\n",
    "    plt.show()\n",
    "\n",
    "    return w, b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Loss 1745.5521550979392, Weight -0.18797553171664952, Bias 2.2673045171457513\n",
      "Iteration 2: Loss 1698.9579709467603, Weight -0.3439976311112525, Bias 4.081575113813229\n",
      "Iteration 3: Loss 1669.1079366380663, Weight -0.4733443720343996, Bias 5.533345992466324\n",
      "Iteration 4: Loss 1649.9841290946079, Weight -0.580457661871839, Bias 6.695056504123487\n",
      "Iteration 5: Loss 1637.7317514510453, Weight -0.6690671862405067, Bias 7.62466821931012\n",
      "Iteration 6: Loss 1629.8815114209876, Weight -0.7422981049558978, Bias 8.368558866358585\n",
      "Iteration 7: Loss 1624.8515793383528, Weight -0.8027640639455446, Bias 8.963837726677616\n",
      "Iteration 8: Loss 1621.628596453445, Weight -0.8526471073725101, Bias 9.440198162242678\n",
      "Iteration 9: Loss 1619.5633559203798, Weight -0.8937660242768835, Bias 9.821399819107194\n",
      "Iteration 10: Loss 1618.2399285522865, Weight -0.9276345714052336, Bias 10.126454545459634\n",
      "Iteration 11: Loss 1617.3918296898971, Weight -0.9555108975109259, Bias 10.370575258321285\n",
      "Iteration 12: Loss 1616.8483168432629, Weight -0.9784393673662303, Bias 10.565935149170848\n",
      "Iteration 13: Loss 1616.4999874081623, Weight -0.9972858548583929, Bias 10.72227514344659\n",
      "Iteration 14: Loss 1616.2767393808654, Weight -1.0127674495867862, Bias 10.847389948315676\n",
      "Iteration 15: Loss 1616.1336517015716, Weight -1.0254774038683843, Bias 10.947516958367633\n",
      "Iteration 16: Loss 1616.0419380326807, Weight -1.0359060389677033, Bias 11.027647436835764\n",
      "Iteration 17: Loss 1615.983150778999, Weight -1.0444582315904554, Bias 11.091775508062417\n",
      "Iteration 18: Loss 1615.9454674194621, Weight -1.0514680143853647, Bias 11.143097391191437\n",
      "Iteration 19: Loss 1615.9213109505654, Weight -1.0572107470798506, Bias 11.184170820286894\n",
      "Iteration 20: Loss 1615.9058251115487, Weight -1.061913247334504, Bias 11.217042608074582\n",
      "Iteration 21: Loss 1615.895897299712, Weight -1.0657622116763315, Bias 11.243350719947268\n",
      "Iteration 22: Loss 1615.8895324244502, Weight -1.0689112061243085, Bias 11.26440595229688\n",
      "Iteration 23: Loss 1615.8854516379681, Weight -1.071486462500302, Bias 11.281257291059338\n",
      "Iteration 24: Loss 1615.8828351694442, Weight -1.0735916790951971, Bias 11.294744211716633\n",
      "Iteration 25: Loss 1615.8811575058685, Weight -1.0753119925534633, Bias 11.305538530203108\n",
      "Iteration 26: Loss 1615.88008175426, Weight -1.07671726083037, Bias 11.314177892652557\n",
      "Iteration 27: Loss 1615.8793919324066, Weight -1.0778647742136462, Bias 11.32109257465307\n",
      "Iteration 28: Loss 1615.8789495684282, Weight -1.0788014921038211, Bias 11.326626926808952\n",
      "Iteration 29: Loss 1615.8786658807521, Weight -1.0795658870006068, Bias 11.331056536271056\n",
      "Iteration 30: Loss 1615.8784839445452, Weight -1.0801894634959102, Bias 11.334601960149639\n",
      "Iteration 31: Loss 1615.878367259339, Weight -1.0806980086354234, Bias 11.337439715695005\n",
      "Iteration 32: Loss 1615.8782924199052, Weight -1.0811126204414327, Bias 11.339711075282196\n",
      "Iteration 33: Loss 1615.8782444174703, Weight -1.0814505533981795, Bias 11.341529104735013\n",
      "Iteration 34: Loss 1615.8782136271539, Weight -1.0817259130384123, Bias 11.342984295905742\n",
      "Iteration 35: Loss 1615.8781938764225, Weight -1.0819502262231926, Bias 11.344149074316666\n",
      "Iteration 36: Loss 1615.8781812066031, Weight -1.082132909095978, Bias 11.345081406568664\n",
      "Iteration 37: Loss 1615.87817307875, Weight -1.082281650863693, Bias 11.345827687331036\n",
      "Iteration 38: Loss 1615.878167864408, Weight -1.0824027283828739, Bias 11.346425049805115\n",
      "Iteration 39: Loss 1615.8781645190577, Weight -1.082501263899365, Bias 11.346903214809727\n",
      "Iteration 40: Loss 1615.8781623727014, Weight -1.0825814361141959, Bias 11.347285970635022\n",
      "Iteration 41: Loss 1615.878160995554, Weight -1.0826466529496594, Bias 11.347592357404967\n",
      "Iteration 42: Loss 1615.8781601119097, Weight -1.0826996929041912, Bias 11.34783761495976\n",
      "Iteration 43: Loss 1615.878159544897, Weight -1.0827428206589984, Bias 11.348033941482871\n",
      "Iteration 44: Loss 1615.8781591810432, Weight -1.082777881588867, Bias 11.34819110066526\n",
      "Iteration 45: Loss 1615.8781589475475, Weight -1.0828063789971054, Bias 11.348316907651427\n",
      "Iteration 46: Loss 1615.8781587977, Weight -1.0828295372092767, Bias 11.348417617971696\n",
      "Iteration 47: Loss 1615.87815870153, Weight -1.0828483530966175, Bias 11.348498238831365\n",
      "Iteration 48: Loss 1615.8781586398075, Weight -1.0828636381365924, Bias 11.348562778259039\n",
      "Iteration 49: Loss 1615.878158600191, Weight -1.0828760527372525, Bias 11.348614444520866\n",
      "Iteration 50: Loss 1615.8781585747627, Weight -1.082886134239445, Bias 11.348655805729862\n",
      "Iteration 51: Loss 1615.8781585584404, Weight -1.082894319754351, Bias 11.348688917597006\n",
      "Iteration 52: Loss 1615.8781585479626, Weight -1.082900964783419, Bias 11.348715425683967\n",
      "Iteration 53: Loss 1615.8781585412369, Weight -1.082906358395264, Bias 11.348736647247597\n",
      "Iteration 54: Loss 1615.8781585369184, Weight -1.0829107355927838, Bias 11.34875363674999\n",
      "Iteration 55: Loss 1615.8781585341465, Weight -1.0829142873879913, Bias 11.348767238294627\n",
      "Iteration 56: Loss 1615.8781585323666, Weight -1.0829171690073371, Bias 11.348778127598175\n",
      "Iteration 57: Loss 1615.8781585312238, Weight -1.082919506572758, Bias 11.34878684558656\n",
      "Iteration 58: Loss 1615.8781585304903, Weight -1.0829214025402993, Bias 11.348793825287002\n",
      "Iteration 59: Loss 1615.878158530019, Weight -1.0829229401263227, Bias 11.348799413354012\n",
      "Iteration 60: Loss 1615.8781585297163, Weight -1.0829241869089372, Bias 11.348803887300217\n",
      "Iteration 61: Loss 1615.8781585295226, Weight -1.0829251977577032, Bias 11.348807469289227\n",
      "Iteration 62: Loss 1615.8781585293973, Weight -1.0829260172163873, Bias 11.348810337176559\n",
      "Iteration 63: Loss 1615.8781585293173, Weight -1.0829266814404748, Bias 11.348812633347809\n",
      "Iteration 64: Loss 1615.8781585292659, Weight -1.0829272197723223, Bias 11.348814471793581\n",
      "Iteration 65: Loss 1615.8781585292327, Weight -1.0829276560214698, Bias 11.34881594377301\n",
      "Iteration 66: Loss 1615.8781585292118, Weight -1.0829280095051015, Bias 11.348817122347485\n",
      "Iteration 67: Loss 1615.878158529198, Weight -1.0829282958934345, Bias 11.348818066009997\n",
      "Iteration 68: Loss 1615.8781585291892, Weight -1.0829285278964849, Bias 11.348818821590532\n",
      "Iteration 69: Loss 1615.8781585291838, Weight -1.0829287158218723, Bias 11.348819426581953\n",
      "Iteration 70: Loss 1615.8781585291802, Weight -1.0829288680278122, Bias 11.348819911001957\n",
      "Iteration 71: Loss 1615.8781585291777, Weight -1.0829289912909152, Bias 11.348820298883693\n",
      "Iteration 72: Loss 1615.878158529176, Weight -1.0829290911047822, Bias 11.348820609469072\n",
      "Iteration 73: Loss 1615.8781585291754, Weight -1.0829291719223662, Bias 11.348820858164101\n",
      "Iteration 74: Loss 1615.8781585291747, Weight -1.0829292373526678, Bias 11.348821057303699\n",
      "Iteration 75: Loss 1615.8781585291745, Weight -1.0829292903203436, Bias 11.348821216764001\n",
      "Iteration 76: Loss 1615.8781585291738, Weight -1.0829293331951995, Bias 11.34882134445256\n",
      "Iteration 77: Loss 1615.8781585291738, Weight -1.082929367897239, Bias 11.348821446700795\n",
      "Iteration 78: Loss 1615.8781585291736, Weight -1.0829293959818673, Bias 11.348821528578208\n",
      "Iteration 79: Loss 1615.8781585291738, Weight -1.0829294187089908, Bias 11.348821594143931\n",
      "Iteration 80: Loss 1615.8781585291736, Weight -1.0829294370990499, Bias 11.348821646648135\n",
      "Iteration 81: Loss 1615.8781585291733, Weight -1.0829294519784474, Bias 11.34882168869327\n",
      "Iteration 82: Loss 1615.8781585291733, Weight -1.0829294640163776, Bias 11.348821722363176\n",
      "Iteration 83: Loss 1615.8781585291736, Weight -1.0829294737546804, Bias 11.348821749326445\n",
      "Iteration 84: Loss 1615.8781585291736, Weight -1.0829294816320338, Bias 11.348821770919182\n",
      "Iteration 85: Loss 1615.8781585291736, Weight -1.0829294880035625, Bias 11.348821788211264\n",
      "Iteration 86: Loss 1615.8781585291736, Weight -1.0829294931567246, Bias 11.348821802059403\n",
      "Iteration 87: Loss 1615.8781585291733, Weight -1.0829294973241852, Bias 11.348821813149618\n",
      "Iteration 88: Loss 1615.8781585291733, Weight -1.082929500694242, Bias 11.348821822031256\n",
      "Iteration 89: Loss 1615.8781585291736, Weight -1.0829295034192743, Bias 11.348821829144224\n",
      "Iteration 90: Loss 1615.8781585291736, Weight -1.082929505622583, Bias 11.348821834840788\n",
      "Iteration 91: Loss 1615.8781585291736, Weight -1.0829295074039307, Bias 11.348821839403042\n",
      "Iteration 92: Loss 1615.8781585291733, Weight -1.08292950884403, Bias 11.348821843056893\n",
      "Iteration 93: Loss 1615.8781585291733, Weight -1.0829295100081746, Bias 11.348821845983245\n",
      "Iteration 94: Loss 1615.8781585291736, Weight -1.0829295109491817, Bias 11.34882184832697\n",
      "Iteration 95: Loss 1615.8781585291736, Weight -1.082929511709772, Bias 11.348821850204088\n",
      "Iteration 96: Loss 1615.8781585291738, Weight -1.0829295123244964, Bias 11.348821851707509\n",
      "Iteration 97: Loss 1615.8781585291733, Weight -1.0829295128212988, Bias 11.348821852911643\n",
      "Iteration 98: Loss 1615.8781585291736, Weight -1.082929513222775, Bias 11.348821853876078\n",
      "Iteration 99: Loss 1615.8781585291736, Weight -1.0829295135471964, Bias 11.34882185464854\n",
      "Iteration 100: Loss 1615.8781585291736, Weight -1.0829295138093362, Bias 11.348821855267245\n",
      "Iteration 101: Loss 1615.8781585291736, Weight -1.0829295140211395, Bias 11.348821855762804\n",
      "Iteration 102: Loss 1615.8781585291736, Weight -1.0829295141922612, Bias 11.348821856159732\n",
      "Iteration 103: Loss 1615.8781585291733, Weight -1.0829295143305078, Bias 11.348821856477665\n",
      "Iteration 104: Loss 1615.8781585291733, Weight -1.0829295144421887, Bias 11.348821856732325\n",
      "Iteration 105: Loss 1615.8781585291736, Weight -1.0829295145324038, Bias 11.348821856936306\n",
      "Iteration 106: Loss 1615.8781585291736, Weight -1.082929514605275, Bias 11.348821857099695\n",
      "Iteration 107: Loss 1615.8781585291736, Weight -1.0829295146641338, Bias 11.348821857230572\n",
      "Iteration 108: Loss 1615.8781585291733, Weight -1.082929514711672, Bias 11.348821857335409\n",
      "Iteration 109: Loss 1615.8781585291736, Weight -1.0829295147500648, Bias 11.348821857419386\n",
      "Iteration 110: Loss 1615.8781585291736, Weight -1.0829295147810702, Bias 11.348821857486655\n",
      "Iteration 111: Loss 1615.8781585291733, Weight -1.0829295148061089, Bias 11.34882185754054\n",
      "Iteration 112: Loss 1615.8781585291733, Weight -1.0829295148263274, Bias 11.348821857583706\n",
      "Iteration 113: Loss 1615.8781585291733, Weight -1.082929514842653, Bias 11.348821857618285\n",
      "Iteration 114: Loss 1615.8781585291738, Weight -1.0829295148558349, Bias 11.348821857645984\n",
      "Iteration 115: Loss 1615.8781585291733, Weight -1.0829295148664777, Bias 11.348821857668172\n",
      "Iteration 116: Loss 1615.8781585291733, Weight -1.0829295148750702, Bias 11.348821857685948\n",
      "Iteration 117: Loss 1615.8781585291736, Weight -1.082929514882007, Bias 11.348821857700187\n",
      "Iteration 118: Loss 1615.8781585291736, Weight -1.082929514887607, Bias 11.348821857711595\n",
      "Iteration 119: Loss 1615.8781585291736, Weight -1.0829295148921279, Bias 11.348821857720733\n",
      "Iteration 120: Loss 1615.8781585291736, Weight -1.082929514895777, Bias 11.348821857728053\n",
      "Iteration 121: Loss 1615.8781585291736, Weight -1.0829295148987224, Bias 11.348821857733919\n",
      "Iteration 122: Loss 1615.8781585291733, Weight -1.0829295149010996, Bias 11.348821857738617\n",
      "Iteration 123: Loss 1615.8781585291733, Weight -1.0829295149030183, Bias 11.348821857742381\n",
      "Iteration 124: Loss 1615.8781585291733, Weight -1.0829295149045668, Bias 11.348821857745397\n",
      "Iteration 125: Loss 1615.8781585291733, Weight -1.0829295149058167, Bias 11.348821857747813\n",
      "Iteration 126: Loss 1615.8781585291733, Weight -1.0829295149068252, Bias 11.34882185774975\n",
      "Iteration 127: Loss 1615.8781585291733, Weight -1.082929514907639, Bias 11.3488218577513\n",
      "Iteration 128: Loss 1615.8781585291733, Weight -1.0829295149082956, Bias 11.348821857752544\n",
      "Iteration 129: Loss 1615.8781585291736, Weight -1.0829295149088254, Bias 11.34882185775354\n",
      "Iteration 130: Loss 1615.8781585291736, Weight -1.082929514909253, Bias 11.348821857754338\n",
      "Iteration 131: Loss 1615.8781585291736, Weight -1.0829295149095979, Bias 11.348821857754977\n",
      "Iteration 132: Loss 1615.8781585291736, Weight -1.0829295149098763, Bias 11.348821857755489\n",
      "Iteration 133: Loss 1615.8781585291736, Weight -1.0829295149101013, Bias 11.3488218577559\n",
      "Iteration 134: Loss 1615.8781585291736, Weight -1.0829295149102822, Bias 11.34882185775623\n",
      "Iteration 135: Loss 1615.8781585291733, Weight -1.0829295149104283, Bias 11.348821857756493\n",
      "Iteration 136: Loss 1615.8781585291736, Weight -1.082929514910546, Bias 11.348821857756704\n",
      "Iteration 137: Loss 1615.8781585291733, Weight -1.082929514910641, Bias 11.348821857756873\n",
      "Iteration 138: Loss 1615.8781585291736, Weight -1.082929514910718, Bias 11.348821857757008\n",
      "Iteration 139: Loss 1615.8781585291736, Weight -1.0829295149107798, Bias 11.348821857757116\n",
      "Iteration 140: Loss 1615.8781585291733, Weight -1.0829295149108298, Bias 11.348821857757203\n",
      "Iteration 141: Loss 1615.8781585291736, Weight -1.08292951491087, Bias 11.348821857757274\n",
      "Iteration 142: Loss 1615.8781585291736, Weight -1.0829295149109028, Bias 11.348821857757331\n",
      "Iteration 143: Loss 1615.8781585291733, Weight -1.082929514910929, Bias 11.348821857757375\n",
      "Iteration 144: Loss 1615.8781585291736, Weight -1.0829295149109501, Bias 11.348821857757411\n",
      "Iteration 145: Loss 1615.8781585291736, Weight -1.0829295149109672, Bias 11.34882185775744\n",
      "Iteration 146: Loss 1615.8781585291733, Weight -1.082929514910981, Bias 11.348821857757462\n",
      "Iteration 147: Loss 1615.8781585291736, Weight -1.082929514910992, Bias 11.348821857757482\n",
      "Iteration 148: Loss 1615.8781585291736, Weight -1.082929514911001, Bias 11.348821857757496\n",
      "Iteration 149: Loss 1615.8781585291733, Weight -1.0829295149110083, Bias 11.348821857757509\n",
      "Iteration 150: Loss 1615.8781585291736, Weight -1.082929514911014, Bias 11.34882185775752\n",
      "Iteration 151: Loss 1615.8781585291733, Weight -1.0829295149110187, Bias 11.348821857757526\n",
      "Iteration 152: Loss 1615.8781585291733, Weight -1.0829295149110225, Bias 11.348821857757532\n",
      "Iteration 153: Loss 1615.8781585291733, Weight -1.0829295149110256, Bias 11.348821857757537\n",
      "Iteration 154: Loss 1615.8781585291736, Weight -1.082929514911028, Bias 11.34882185775754\n",
      "Iteration 155: Loss 1615.8781585291736, Weight -1.08292951491103, Bias 11.348821857757544\n",
      "Iteration 156: Loss 1615.8781585291736, Weight -1.0829295149110318, Bias 11.348821857757546\n",
      "Iteration 157: Loss 1615.8781585291736, Weight -1.0829295149110334, Bias 11.348821857757548\n",
      "Iteration 158: Loss 1615.8781585291736, Weight -1.0829295149110345, Bias 11.34882185775755\n",
      "Iteration 159: Loss 1615.8781585291736, Weight -1.0829295149110354, Bias 11.34882185775755\n",
      "Iteration 160: Loss 1615.8781585291736, Weight -1.082929514911036, Bias 11.34882185775755\n",
      "Iteration 161: Loss 1615.8781585291736, Weight -1.0829295149110365, Bias 11.34882185775755\n",
      "Iteration 162: Loss 1615.8781585291736, Weight -1.082929514911037, Bias 11.34882185775755\n",
      "Iteration 163: Loss 1615.8781585291736, Weight -1.0829295149110372, Bias 11.34882185775755\n",
      "Iteration 164: Loss 1615.8781585291736, Weight -1.0829295149110374, Bias 11.34882185775755\n",
      "Iteration 165: Loss 1615.8781585291736, Weight -1.0829295149110376, Bias 11.34882185775755\n",
      "Iteration 166: Loss 1615.8781585291736, Weight -1.0829295149110378, Bias 11.34882185775755\n",
      "Iteration 167: Loss 1615.8781585291736, Weight -1.082929514911038, Bias 11.34882185775755\n",
      "Iteration 168: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 169: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 170: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 171: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 172: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 173: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 174: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 175: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 176: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 177: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 178: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 179: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 180: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 181: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 182: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 183: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 184: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 185: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 186: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 187: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 188: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 189: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 190: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 191: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 192: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 193: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 194: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 195: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 196: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 197: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 198: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 199: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 200: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 201: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 202: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 203: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 204: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 205: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 206: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 207: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 208: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 209: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 210: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 211: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 212: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 213: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 214: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 215: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 216: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 217: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 218: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 219: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 220: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 221: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 222: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 223: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 224: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 225: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 226: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 227: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 228: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 229: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 230: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 231: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 232: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 233: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 234: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 235: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 236: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 237: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 238: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 239: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 240: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 241: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 242: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 243: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 244: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 245: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 246: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 247: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 248: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 249: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 250: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 251: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 252: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 253: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 254: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 255: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 256: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 257: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 258: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 259: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 260: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 261: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 262: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 263: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 264: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 265: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 266: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 267: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 268: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 269: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 270: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 271: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 272: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 273: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 274: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 275: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 276: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 277: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 278: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 279: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 280: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 281: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 282: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 283: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 284: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 285: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 286: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 287: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 288: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 289: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 290: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 291: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 292: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 293: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 294: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 295: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 296: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 297: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 298: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 299: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 300: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 301: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 302: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 303: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 304: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 305: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 306: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 307: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 308: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 309: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 310: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 311: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 312: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 313: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 314: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 315: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 316: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 317: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 318: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 319: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 320: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 321: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 322: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 323: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 324: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 325: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 326: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 327: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 328: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 329: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 330: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 331: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 332: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 333: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 334: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 335: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 336: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 337: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 338: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 339: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 340: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 341: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 342: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 343: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 344: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 345: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 346: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 347: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 348: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 349: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 350: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 351: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 352: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 353: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 354: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 355: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 356: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 357: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 358: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 359: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 360: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 361: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 362: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 363: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 364: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 365: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 366: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 367: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 368: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 369: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 370: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 371: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 372: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 373: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 374: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 375: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 376: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 377: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 378: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 379: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 380: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 381: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 382: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 383: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 384: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 385: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 386: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 387: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 388: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 389: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 390: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 391: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 392: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 393: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 394: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 395: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 396: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 397: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 398: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 399: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 400: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 401: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 402: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 403: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 404: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 405: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 406: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 407: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 408: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 409: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 410: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 411: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 412: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 413: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 414: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 415: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 416: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 417: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 418: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 419: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 420: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 421: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 422: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 423: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 424: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 425: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 426: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 427: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 428: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 429: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 430: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 431: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 432: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 433: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 434: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 435: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 436: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 437: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 438: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 439: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 440: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 441: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 442: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 443: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 444: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 445: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 446: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 447: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 448: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 449: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 450: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 451: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 452: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 453: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 454: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 455: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 456: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 457: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 458: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 459: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 460: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 461: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 462: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 463: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 464: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 465: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 466: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 467: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 468: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 469: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 470: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 471: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 472: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 473: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 474: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 475: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 476: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 477: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 478: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 479: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 480: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 481: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 482: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 483: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 484: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 485: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 486: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 487: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 488: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 489: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 490: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 491: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 492: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 493: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 494: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 495: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 496: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 497: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 498: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 499: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 500: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 501: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 502: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 503: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 504: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 505: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 506: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 507: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 508: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 509: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 510: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 511: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 512: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 513: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 514: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 515: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 516: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 517: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 518: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 519: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 520: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 521: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 522: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 523: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 524: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 525: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 526: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 527: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 528: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 529: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 530: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 531: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 532: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 533: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 534: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 535: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 536: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 537: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 538: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 539: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 540: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 541: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 542: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 543: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 544: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 545: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 546: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 547: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 548: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 549: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 550: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 551: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 552: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 553: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 554: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 555: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 556: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 557: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 558: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 559: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 560: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 561: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 562: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 563: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 564: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 565: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 566: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 567: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 568: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 569: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 570: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 571: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 572: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 573: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 574: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 575: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 576: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 577: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 578: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 579: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 580: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 581: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 582: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 583: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 584: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 585: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 586: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 587: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 588: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 589: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 590: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 591: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 592: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 593: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 594: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 595: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 596: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 597: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 598: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 599: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 600: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 601: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 602: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 603: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 604: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 605: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 606: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 607: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 608: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 609: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 610: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 611: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 612: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 613: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 614: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 615: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 616: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 617: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 618: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 619: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 620: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 621: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 622: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 623: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 624: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 625: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 626: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 627: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 628: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 629: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 630: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 631: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 632: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 633: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 634: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 635: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 636: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 637: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 638: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 639: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 640: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 641: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 642: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 643: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 644: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 645: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 646: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 647: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 648: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 649: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 650: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 651: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 652: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 653: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 654: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 655: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 656: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 657: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 658: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 659: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 660: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 661: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 662: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 663: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 664: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 665: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 666: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 667: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 668: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 669: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 670: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 671: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 672: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 673: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 674: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 675: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 676: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 677: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 678: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 679: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 680: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 681: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 682: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 683: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 684: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 685: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 686: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 687: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 688: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 689: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 690: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 691: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 692: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 693: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 694: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 695: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 696: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 697: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 698: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 699: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 700: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 701: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 702: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 703: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 704: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 705: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 706: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 707: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 708: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 709: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 710: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 711: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 712: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 713: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 714: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 715: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 716: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 717: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 718: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 719: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 720: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 721: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 722: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 723: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 724: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 725: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 726: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 727: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 728: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 729: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 730: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 731: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 732: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 733: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 734: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 735: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 736: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 737: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 738: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 739: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 740: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 741: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 742: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 743: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 744: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 745: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 746: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 747: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 748: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 749: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 750: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 751: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 752: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 753: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 754: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 755: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 756: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 757: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 758: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 759: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 760: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 761: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 762: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 763: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 764: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 765: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 766: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 767: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 768: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 769: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 770: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 771: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 772: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 773: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 774: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 775: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 776: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 777: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 778: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 779: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 780: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 781: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 782: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 783: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 784: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 785: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 786: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 787: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 788: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 789: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 790: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 791: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 792: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 793: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 794: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 795: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 796: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 797: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 798: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 799: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 800: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 801: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 802: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 803: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 804: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 805: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 806: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 807: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 808: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 809: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 810: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 811: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 812: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 813: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 814: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 815: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 816: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 817: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 818: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 819: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 820: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 821: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 822: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 823: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 824: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 825: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 826: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 827: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 828: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 829: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 830: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 831: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 832: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 833: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 834: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 835: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 836: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 837: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 838: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 839: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 840: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 841: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 842: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 843: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 844: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 845: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 846: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 847: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 848: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 849: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 850: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 851: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 852: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 853: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 854: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 855: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 856: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 857: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 858: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 859: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 860: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 861: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 862: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 863: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 864: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 865: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 866: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 867: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 868: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 869: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 870: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 871: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 872: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 873: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 874: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 875: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 876: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 877: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 878: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 879: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 880: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 881: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 882: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 883: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 884: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 885: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 886: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 887: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 888: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 889: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 890: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 891: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 892: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 893: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 894: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 895: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 896: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 897: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 898: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 899: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 900: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 901: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 902: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 903: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 904: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 905: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 906: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 907: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 908: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 909: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 910: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 911: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 912: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 913: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 914: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 915: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 916: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 917: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 918: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 919: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 920: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 921: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 922: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 923: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 924: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 925: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 926: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 927: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 928: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 929: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 930: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 931: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 932: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 933: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 934: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 935: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 936: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 937: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 938: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 939: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 940: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 941: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 942: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 943: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 944: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 945: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 946: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 947: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 948: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 949: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 950: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 951: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 952: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 953: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 954: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 955: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 956: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 957: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 958: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 959: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 960: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 961: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 962: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 963: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 964: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 965: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 966: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 967: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 968: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 969: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 970: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 971: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 972: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 973: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 974: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 975: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 976: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 977: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 978: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 979: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 980: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 981: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 982: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 983: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 984: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 985: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 986: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 987: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 988: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 989: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 990: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 991: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 992: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 993: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 994: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 995: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 996: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 997: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 998: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 999: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n",
      "Iteration 1000: Loss 1615.8781585291736, Weight -1.0829295149110383, Bias 11.34882185775755\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Weight: -1.0829295149110383\n",
      "Estimated Bias: 11.34882185775755\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "est_weight, est_bias = train_model(X_train, y_train, alpha, max_epoch)\n",
    "print(f\"Estimated Weight: {est_weight}\\nEstimated Bias: {est_bias}\")\n",
    "y_pred = est_weight*y_test + est_bias\n",
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(X_test, y_test, marker='o', color='red')\n",
    "\n",
    "plt.plot([min(X_test), max(X_test)], [min(y_pred), max(y_pred)], color='blue', label=\"line1\")\n",
    "plt.plot([min(X_test), max(X_test)], [min(y_test), max(y_test)], color='orange', label=\"line2\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.58402315414033\n",
      "6783.597746511149\n",
      "-3.4195791818428587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "print(r2_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}